function deriveCameraPosition(subject, cornealCoord, varargin)
% Derive a vector of relative position of the eye from fMRI motion params
%
% Syntax:
%  deriveCameraPosition(subjectCellArray, cornealCoords)
%
% Description:
%
%
%
% Dimensions of the T1 image as expressed in Flywheel viewer

% Examples:
%{
    % The coords were obtained within the Flywheel image viewer for the
    % right cornea from the T1w_acpc_dc_restore.nii.gz image generated by
    % the hcp-struct gear. These coordinates are in the order
    % superior-inferior, anterior-posterior, left-right
    dataArray = {...
                'TOME_3001', [189 29 160]; ...
                'TOME_3002', [190 23 162]; ...
                'TOME_3003', [187 24 154]; ...
                'TOME_3004', [194 33 151]; ...
                'TOME_3005', [180 35 157]; ...
                'TOME_3007', [194 31 157]; ...
                'TOME_3008', [194 35 153]; ...
                'TOME_3009', [194 35 152]; ...
                'TOME_3011', [188 32 158]; ...
                'TOME_3012', [185 28 158]; ...
                'TOME_3013', [184 34 157]; ...
                'TOME_3014', [194 30 155]; ...
                'TOME_3015', [183 35 155]; ...
                'TOME_3016', [187 34 153]; ...
                'TOME_3017', [186 38 155]; ...
                'TOME_3018', [195 31 158]; ...
                'TOME_3019', [189 35 153]; ...
                'TOME_3020', [189 26 160]; ...
                'TOME_3021', [192 26 155]; ...
                'TOME_3022', [190 33 154]; ...
                'TOME_3023', [192 21 159]; ...
                'TOME_3024', [191 33 152]; ...
                'TOME_3025', [188 30 155]; ...
                'TOME_3026', [189 30 162]; ...
                'TOME_3028', [186 28 164]; ...
                'TOME_3029', [186 38 154]; ...
                'TOME_3030', [188 24 157]; ...
                'TOME_3031', [185 31 159]; ...
                'TOME_3032', [192 35 155]; ...
                'TOME_3033', [190 29 153]; ...
                'TOME_3034', [188 35 151]; ...
                'TOME_3035', [192 29 158]; ...
                'TOME_3036', [194 35 157]; ...
                'TOME_3037', [192 31 155]; ...
                'TOME_3038', [187 35 160]; ...
                'TOME_3039', [183 36 155]; ...
                'TOME_3040', [189 32 155]; ...
                'TOME_3042', [189 28 158]; ...
                'TOME_3043', [192 31 153] ...
                };
    for ii=1:size(dataArray,1)
        deriveCameraPosition(dataArray{ii,1}, dataArray{ii,2})
    end
%}

%% Parse vargin for options passed here
p = inputParser; p.KeepUnmatched = true;

% Required
p.addRequired('subject',@ischar);
p.addRequired('cornealCoord',@isnumeric);

% Optional display and I/O params
p.addParameter('verbose',true,@islogical);
p.addParameter('showPlots',true,@islogical);

% Optional environment params
p.addParameter('tbSnapshot',[],@(x)(isempty(x) | isstruct(x)));
p.addParameter('timestamp',char(datetime('now')),@ischar);
p.addParameter('hostname',char(java.lang.System.getProperty('user.name')),@ischar);
p.addParameter('username',char(java.net.InetAddress.getLocalHost.getHostName),@ischar);

% Optional analysis params
p.addParameter('processingDir','/Users/aguirre/Dropbox (Aguirre-Brainard Lab)/TOME_processing',@ischar);
p.addParameter('analysisDir', '/Users/aguirre/Dropbox (Aguirre-Brainard Lab)/TOME_analysis/deriveCameraPositionFromHeadMotion/',@ischar);
p.addParameter('scratchSaveDir',getpref('flywheelMRSupport','flywheelScratchDir'),@ischar);
p.addParameter('sessionDir','session1_restAndStructure',@ischar);
p.addParameter('freesurferBinDir','/Applications/freesurfer/bin/',@ischar);
p.addParameter('epiVoxelSizeMm', 2, @isnumeric);
p.addParameter('msecsTR', 800, @isnumeric);
p.addParameter('t1Dims', [227 272 227], @isnumeric);


%% Parse and check the parameters
p.parse(subject, cornealCoord, varargin{:});


%% Define some strings used in system calls

% This string precedes system calls to freesurfer commands to set the
% environment variables
freesurferSetUp = 'export FREESURFER_HOME=/Applications/freesurfer; source $FREESURFER_HOME/SetUpFreeSurfer.sh; ';

% This string follows system calls to silence consult output
devNull = ' >/dev/null';


%% Find the right corneal surface coordinate in the EPI scout space

% Load a T1 reference volume
t1FileName = fullfile(p.Results.analysisDir,'T1w_acpc_dc_restore.nii.gz');
mri = MRIread(escapeFileCharacters(t1FileName));
% Place a point in the T1 volume corresponding to the right cornea
mri.vol = mri.vol.*0;
% The coordinates in the flywheel viewer are relative to the opposite
% corner of the volume, so we subtract the value from the dimensions of
% the volume. These dimensions are SAR order..
coord = p.Results.t1Dims-cornealCoord;
% In matlab, the mri.vol dimensions are
% anterior-posterior, right-left, inferior-superior So the flywheel
% viewer coordinate [189 29 160] corresponds to the mri.vol coordinate
% in matlab of
mri.vol(coord(2)+1,coord(3)+1,coord(1)+1)=100;

% Save the volume in a tmp location
t1SpaceEyeCoordFileName = fullfile(p.Results.scratchSaveDir,['t1SpaceEyeCoord_' num2str(tic()) '.nii.gz']);
MRIwrite(mri,escapeFileCharacters(t1SpaceEyeCoordFileName));

% Find the Scout EPI targets in the analysisDir
targetFiles = dir(fullfile(p.Results.analysisDir,p.Results.sessionDir,[subject '*' 'Scout_gdc.nii.gz']));

% Loop through the target files and project the eye coordinate in T1
% space to scout EPI space
for ii=1:length(targetFiles)
    
    % Assemble the file strings
    acquisitionRootName = strsplit(targetFiles(ii).name,'_Scout_gdc.nii.gz');
    acquisitionRootName = acquisitionRootName{1};
    infoFile = fullfile(targetFiles(ii).folder,[acquisitionRootName '_sessionInfo.mat']);
    regFile = fullfile(targetFiles(ii).folder,[acquisitionRootName '_EPItoT1w.dat']);
    moveRegressorsFile = fullfile(targetFiles(ii).folder,[acquisitionRootName '_Movement_Regressors.txt']);
    outEyeVoxelFile = fullfile(p.Results.scratchSaveDir,[num2str(tic()) acquisitionRootName '_eyeVoxel_ScoutSpace.nii.gz']);
    
    % Assemble the vol2vol command
    command = [p.Results.freesurferBinDir 'mri_vol2vol' ...
        ' --mov ' escapeFileCharacters(t1SpaceEyeCoordFileName) ...
        ' --targ ' escapeFileCharacters(fullfile(targetFiles(ii).folder,targetFiles(ii).name)) ...
        ' --o '  escapeFileCharacters(outEyeVoxelFile) ...
        ' --reg ' escapeFileCharacters(regFile) ...
        ' --cubic' ];
    
    % Issue the command
    system([freesurferSetUp command devNull]);
    
    % Load the resulting volume
    mriEyeVoxel = MRIread(escapeFileCharacters(outEyeVoxelFile));
    
    % Find the eye voxel coordinate
    [~,ind] = max(mriEyeVoxel.vol(:));
    [eyeVoxel(1), eyeVoxel(2), eyeVoxel(3)] = ind2sub(size(mriEyeVoxel.vol),ind);
    
    % Find the position of the eyeVoxel in mm relative to the volume
    % center
    eyePositionWRTCenter = (eyeVoxel-size(mriEyeVoxel.vol)./2).*p.Results.epiVoxelSizeMm;
    
    % Conert dimension order to ras
    eyePositionWRTCenter = eyePositionWRTCenter([2 1 3]);
    
    % Determine the corresponding video acquisition stem
    dataLoad = load(infoFile);
    sessionInfo = dataLoad.sessionInfo;
    clear dataLoad
    tmpString = strsplit(acquisitionRootName,[sessionInfo.subject '_' ]);
    tmpString = tmpString{2};
    tmpString = strrep(tmpString,'Run1','run01');
    tmpString = strrep(tmpString,'Run2','run02');
    tmpString = strrep(tmpString,'Run3','run03');
    tmpString = strrep(tmpString,'Run4','run04');
    videoAcqStemName = fullfile(p.Results.processingDir,p.Results.sessionDir,sessionInfo.subject,sessionInfo.date,'EyeTracking',tmpString);
    
    % Create the relativeCameraPosition
    relativeCameraPosition = calcRelativeCameraPosition(moveRegressorsFile, videoAcqStemName, eyePositionWRTCenter, p.Results.msecsTR);
    
    % add meta data
    relativeCameraPosition.meta = p.Results;
    relativeCameraPosition.meta.sessionInfo = sessionInfo;
    
    % Save the relativeCameraPosition variable
    outCameraPositionFile = [videoAcqStemName '_relativeCameraPosition.mat'];
    save(outCameraPositionFile,'relativeCameraPosition');
    
    % Plot the relativeCameraPosition variables
    if p.Results.showPlots
        figure('Name',acquisitionRootName);
        plot(relativeCameraPosition.values(1,:));
        hold on
        plot(relativeCameraPosition.values(2,:));
        plot(relativeCameraPosition.values(3,:));
        ylim([-4 4]);
    end
    
    % Report completion of this step
    if p.Results.verbose
        reportLineOut = sprintf([acquisitionRootName ' eye coords relative to volume center (mm): %d %d %2d'],eyePositionWRTCenter(1),eyePositionWRTCenter(2),eyePositionWRTCenter(3));
        fprintf([reportLineOut ' \n']);
    end
    
    % Clean up the tmp files
    delete([outEyeVoxelFile]);
    delete([outEyeVoxelFile '.lta']);
    delete([outEyeVoxelFile '.reg']);
    
end

% Clean up the T1 space tmp file
delete(t1SpaceEyeCoordFileName);

end % deriveCameraPosition




function relativeCameraPosition = calcRelativeCameraPosition(moveRegressorsFile, videoAcqStemName, eyePositionWRTCenter, msecsTR)

% Load the head motion regressors
movementTable = readtable(moveRegressorsFile,'Delimiter','space','MultipleDelimsAsOne',true);

numTRs = size(movementTable,1);

% Loop over TRs
for ii = 1:numTRs
    
    % Create the rotation matrix. The regressors correspond to pitch, roll,
    % and yaw.
    R.x = [1 0 0; 0 cosd(movementTable{ii,4}) -sind(movementTable{ii,4}); 0 sind(movementTable{ii,4}) cosd(movementTable{ii,4})];
    R.y = [cosd(movementTable{ii,5}) 0 sind(movementTable{ii,5}); 0 1 0; -sind(movementTable{ii,5}) 0 cosd(movementTable{ii,5})];
    R.z = [cosd(movementTable{ii,6}) -sind(movementTable{ii,6}) 0; sind(movementTable{ii,6}) cosd(movementTable{ii,6}) 0; 0 0 1];
    Rzyx = R.z * R.y * R.x;
    
    % Rotate the eye position
    newEyePosition = Rzyx * eyePositionWRTCenter';
    
    % Translate the eye position. The first three columns of the head
    % motion regressors correspond to x, y, z
    T = table2array(movementTable(ii,1:3));
    newEyePosition = newEyePosition + T';
    
    % Store the newEyePosition
    eyePosition(ii,:)=newEyePosition;
end

% Make eye position relative to the initial time point
eyePosition = eyePosition-eyePosition(1,:);

% Load the eyetracking timebase
dataLoad = load([videoAcqStemName '_timebase.mat']);
timebase = dataLoad.timebase;
clear dataLoad

% Establish the timebase of the scan acquisition
scanTimebase = 0:msecsTR:msecsTR*(numTRs-1);

% Calculate the deltaT of the eyetracking video
eyeTrackDeltaT = mean(diff(timebase.values));

% Establish the timebase of the scan in eyetrack temporal resolution
eyeTrackTimebase = 0:eyeTrackDeltaT:(msecsTR*numTRs)-eyeTrackDeltaT;

% Calculate the number of video frames before and after the scan
% acquisition
nElementsPre = sum(timebase.values<0);
nElementsPost = sum(timebase.values>max(eyeTrackTimebase));

% Create a variable to hold the relative camera position
relativeCameraPosition.values = zeros(3,length(timebase.values));

% We are sometimes off by one frame due to rounding errors and missed
% frames. We fix that here.
trim = (nElementsPre+nElementsPost+numel(eyeTrackTimebase)) - length(timebase.values);
nElementsPost = nElementsPost-trim;

%% Switch axes to camera world coordinates.
% This coordinate frame is in mm units and has the dimensions (X,Y,Z).
% The diagram is of a cartoon head (taken from Leszek Swirski), being
% viewed from above:
%
%    ^
%    |
%    |    .-.
% -Z |   |   | <- Head
%    +   `^u^'
% +Z |      
%    |      
%    |      W <- Camera    (As seen from above)
%    V     
%
%     <-----+----->
%        -X   +X
%
% +X = right
% +Y = up
% +Z = front (towards the camera)

% The scanner coordinates x,y,z correspond to right-left,
% posterior-anterior, inferior-superior. The camera world coordinates are
% x,y,z corresponding to right-left, down-up, back-front (towards the
% camera)
scanToCameraCoords = [1,3,2];
scanToCameraSign = [-1,1,-1];

% Loop over the world coordinate dimensions and create the relative camera
% position vector, with a length equal to the timebase of the video
% acquisition. Interpolate from the coarse TR sampling to the fine video
% sampling.
for dd = 1:3
    relativeCameraPosition.values(scanToCameraCoords(dd),:) = scanToCameraSign(dd) .* ...
        [zeros(1,nElementsPre) ...
        -interp1(scanTimebase,eyePosition(:,dd),eyeTrackTimebase,'PCHIP') ...
        -repmat(eyePosition(end,dd),1,nElementsPost)];
end

end



function nameOut = escapeFileCharacters(nameIn)
% Sanitize file strings to be used in system commands

nameOut = strrep(nameIn,' ','\ ');
nameOut = strrep(nameOut,'(','\(');
nameOut = strrep(nameOut,')','\)');
end